{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NN.TRANSFORMER 와 TORCHTEXT 로 시퀀스-투-시퀀스(SEQUENCE-TO-SEQUENCE) 모델링하기\n",
        "\n",
        "이 튜토리얼에서는 nn.Transformer 모듈을 이용하는 Seq2Seq 모델을 학습하는 방법을 배워보겠습니다.\n",
        "\n",
        "PyTorch 1.2 버젼에는 Attention is All You Need 논문에 기반한 표준 트랜스포머(transformer) 모듈을 포함하고 있습니다. 트랜스포머 모델은 다양한 seq2seq 문제들에서 더 병렬화가 가능하면서 RNN과 비교하여 더 나은 성능을 보임이 입증되었다. \n",
        "\n",
        "nn.Transformer 모듈은 입력과 출력 사이의 전역적인 의존성을 나타내기 위해 nn.MultiheadAttention에 전적으로 의존한다. \n",
        "\n",
        "현재 nn.Transformer 모듈은 모듈화가 잘 되어 있어 단일 컴포넌트로 쉽게 적용 및 구성할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/junghwankim/Desktop/pytorch_tutorial/Seq2Seq_tutorial/transformer_architecture.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 모델 정의하기\n",
        "\n",
        "이 튜토리얼에서 우리는 nn.TransformerEncoder 모델을 Language modeling 과제에 대해서 학습시킬 것이다. 언어 모델링 과제는 주어진 단어가 다음에 이어지는 단어 시퀀스를 따를 likelihood에 대한 확률을 할당하는 것이다. \n",
        "\n",
        "먼저, 토큰들의 시퀀스가 임베딩 레이어로 전달되며, 이어서 포지셔널 인코딩 레이어가 각 단어의 순서를 설명한다. \n",
        "\n",
        "nn.TransformerEncoder는 여러 개의 nn.TransformerEncoderLayer로 구성되어 있다. nn.TransformerEncoder 내부의 셀프-어텐션 레이어들은 시퀀스 안에서의 이전 포지션에만 집중하도록 허용되기 때문에 입력순서와 함께 정사각 형태의 어텐션 마스크가 필요하다. 언어 모델링 과제를 위해 미래의 포지션에 있는 모든 토큰들은 마스킹 되어 가려져야 한다. 실제 단어를 얻기 위해, nn.TransformerEncoder의 출력은 로그-소프트맥스로 이어지는 최종 선형 레이어로 전달된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, d_model)\n",
        "        self.d_model = d_model\n",
        "        self.decoder = nn.Linear(d_model, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
        "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
        "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``PositionalEncoding`` 모듈은 시퀀스 안에서 토큰의 상대적인 또는 절대적인 포지션에 대한 어떤 정보를 주입합니다.\n",
        "포지셔널 인코딩은 임베딩과 합칠 수 있도록 똑같은 차원을 가집니다.\n",
        "여기에서, 우리는 다른 주파수(frequency) 의 ``sine`` 과 ``cosine`` 함수를 사용합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 데이터 로드하고 배치 만들기\n",
        "\n",
        "이 튜토리얼에서는 torchtext를 사용하여 Wikitext-2 데이터셋을 생성합니다.\n",
        "단어 오브젝트는 훈련 데이터셋에 의하여 만들어지고, 토큰을 텐서로 수치화하는데 사용합니다. Wikitext-2에서 보기 드믄 토근은 unk 로 표현됩니다.\n",
        "\n",
        "주어진 1D 벡터의 시퀀스 데이터에서, batchify() 함수는 데이터를 batch_size 컬럼들로 정렬합니다. 만약 데이터가 batch_size 컬럼으로 나누어 떨어지지 않으면, 데이터를 잘라내서 맞춥니다.\n",
        "\n",
        "예로, 아래의 그림과 같이 batch_size =4 일때, 알파벳은 길이가 6인 4개의 시퀀스로 나눠집니다.\n",
        "![](/Users/junghwankim/Desktop/pytorch_tutorial/Seq2Seq_tutorial/figure.png)\n",
        "\n",
        "배치 작업은 더 많은 병렬 처리를 가능하게 하지만, 모델이 독립적으로 각 컬럼들을 취급해야 함을 뜻한다. 예를 들어, 위 예제에서 G와 F의 의존성은 학습되지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
        "\n",
        "# train_iter was \"consumed\" by the process of building the vocab,\n",
        "# so we have to create it again\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
        "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
        "    that wouldn't cleanly fit.\n",
        "\n",
        "    Args:\n",
        "        data: Tensor, shape [N]\n",
        "        bsz: int, batch size\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape [N // bsz, bsz]\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# input, target 시퀀스를 생성하기 위한 함수\n",
        "\n",
        "`get_batch()` 함수는 트랜스포머 모델을 위한 입력-타겟 시퀀스 쌍을 생성합니다. 이 함수는 소스 데이터를 bptt 길이를 가진 덩어리로 세분화 합니다. 언어 모델링 과제를 위해서, 모델은 다음 단어인 Target이 필요합니다. 예를 들어, bptt의 값이 2 라면 우리는 i=0일 때 다음의 2개의 변수를 얻을 수 있다.\n",
        "\n",
        "![](/Users/junghwankim/Desktop/pytorch_tutorial/Seq2Seq_tutorial/transformer_input_target.png)\n",
        "\n",
        "변수 덩어리는 트랜스포머 모델의 S차원과 일치하는 0차원에 해당합니다. 배치 차원 N은 1차원에 해당합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bptt = 35\n",
        "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        source: Tensor, shape [full_seq_len, batch_size]\n",
        "        i: int\n",
        "\n",
        "    Returns:\n",
        "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
        "        target has shape [seq_len * batch_size]\n",
        "    \"\"\"\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# instance initializing\n",
        "\n",
        "모델의 하이퍼파라미터는 아래와 같이 정의된다.\n",
        "\n",
        "단어 사이즈는 단어 오브젝트의 길이와 일치한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ntokens = len(vocab) # 단어 사전(어휘집)의 크기\n",
        "emsize = 200 # 임베딩 차원\n",
        "d_hid = 200 # nn.TransformerEncoder 에서 피드포워드 네트워크(feedforward network) 모델의 차원\n",
        "nlayers = 2 # nn.TransformerEncoder 내부의 nn.TransformerEncoderLayer 개수\n",
        "nhead = 2 # nn.MultiheadAttention의 헤드 개수\n",
        "dropout = 0.2 # 드랍아웃(dropout) 확률\n",
        "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 모델 실행하기\n",
        "\n",
        "CrossEntropyLoss를 SGD 옵티마이저와 함께 사용.\n",
        "\n",
        "lr = 5.0으로 초기화하고 StepLR 스케쥴러를 사용.\n",
        "\n",
        "학습하는 동안, nn.utils.clip_grad_norm_을 사용하여 gradient exploding을 방지한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0  # 학습률(learning rate)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "    model.train()  # 학습 모드 시작\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "\n",
        "    num_batches = len(train_data) // bptt\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        batch_size = data.size(0)\n",
        "        if batch_size != bptt:  # 마지막 배치에만 적용\n",
        "            src_mask = src_mask[:batch_size, :batch_size]\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # 평가 모드 시작\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(eval_data, i)\n",
        "            batch_size = data.size(0)\n",
        "            if batch_size != bptt:\n",
        "                src_mask = src_mask[:batch_size, :batch_size]\n",
        "            output = model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += batch_size * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "에포크 내에서 반복됩니다. 만약 검증 오차(validation loss) 가 우리가 지금까지 관찰한 것 중 최적이라면 모델을 저장합니다.\n",
        "매 에포크 이후에 학습률을 조절합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 95.78 | loss  8.12 | ppl  3369.12\n",
            "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 96.12 | loss  6.86 | ppl   950.78\n",
            "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 96.46 | loss  6.43 | ppl   619.72\n",
            "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 95.54 | loss  6.29 | ppl   541.27\n",
            "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 96.31 | loss  6.19 | ppl   489.11\n",
            "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 95.26 | loss  6.15 | ppl   470.15\n",
            "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 95.00 | loss  6.12 | ppl   453.55\n",
            "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 96.13 | loss  6.11 | ppl   451.46\n",
            "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 97.42 | loss  6.03 | ppl   414.06\n",
            "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 96.74 | loss  6.01 | ppl   408.79\n",
            "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 95.36 | loss  5.90 | ppl   365.18\n",
            "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 95.48 | loss  5.97 | ppl   391.70\n",
            "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 93.86 | loss  5.95 | ppl   385.01\n",
            "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 96.05 | loss  5.87 | ppl   355.35\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 299.70s | valid loss  5.76 | valid ppl   316.83\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 95.48 | loss  5.86 | ppl   351.47\n",
            "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 95.92 | loss  5.84 | ppl   345.31\n",
            "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 96.05 | loss  5.67 | ppl   289.44\n",
            "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 95.25 | loss  5.70 | ppl   297.87\n",
            "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 97.48 | loss  5.65 | ppl   283.98\n",
            "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 96.88 | loss  5.68 | ppl   292.11\n",
            "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 94.55 | loss  5.68 | ppl   292.79\n",
            "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 95.25 | loss  5.71 | ppl   303.14\n",
            "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 96.10 | loss  5.65 | ppl   284.93\n",
            "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 96.96 | loss  5.67 | ppl   290.44\n",
            "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 98.51 | loss  5.55 | ppl   256.50\n",
            "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 96.60 | loss  5.64 | ppl   282.28\n",
            "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 97.56 | loss  5.64 | ppl   280.32\n",
            "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch 96.56 | loss  5.57 | ppl   263.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 301.89s | valid loss  5.64 | valid ppl   282.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch 96.31 | loss  5.59 | ppl   268.58\n",
            "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch 96.58 | loss  5.61 | ppl   274.33\n",
            "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch 97.59 | loss  5.42 | ppl   225.46\n",
            "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch 95.66 | loss  5.49 | ppl   241.22\n",
            "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch 96.25 | loss  5.44 | ppl   229.31\n",
            "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch 96.87 | loss  5.48 | ppl   240.19\n",
            "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch 96.54 | loss  5.49 | ppl   243.18\n",
            "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch 95.62 | loss  5.51 | ppl   247.60\n",
            "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch 94.53 | loss  5.47 | ppl   236.57\n",
            "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch 97.55 | loss  5.48 | ppl   240.80\n",
            "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch 95.97 | loss  5.36 | ppl   213.09\n",
            "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch 97.60 | loss  5.46 | ppl   235.31\n",
            "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch 96.62 | loss  5.46 | ppl   236.24\n",
            "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch 95.32 | loss  5.40 | ppl   222.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 301.28s | valid loss  5.59 | valid ppl   268.73\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 3\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model)\n",
        "    val_loss = evaluate(model, val_data)\n",
        "    val_ppl = math.exp(val_loss)\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    print('-' * 89)\n",
        "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = copy.deepcopy(model)\n",
        "\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "평가 데이터셋(test dataset)으로 모델을 평가하기\n",
        "-------------------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================================================================================\n",
            "| End of training | test loss  5.51 | test ppl   247.46\n",
            "=========================================================================================\n"
          ]
        }
      ],
      "source": [
        "test_loss = evaluate(best_model, test_data)\n",
        "test_ppl = math.exp(test_loss)\n",
        "print('=' * 89)\n",
        "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
        "      f'test ppl {test_ppl:8.2f}')\n",
        "print('=' * 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "704802e396c47ec2fbe49fdd63907b8569bda7598820a76a954d72ad341bac6c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
